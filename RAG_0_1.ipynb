{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMx1Z24NszQ27VJoG0YNdNR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e66ea9c0c904c3a8e49b77670e642e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e09e639ccc4c446090d6c0ad53fd6316",
              "IPY_MODEL_4cf551728dc44a71b6ad6ceee06e3e48",
              "IPY_MODEL_be9503a14c4b411bbcf4ed5245dc9c88"
            ],
            "layout": "IPY_MODEL_6696d694b72f449da36c6f85163dbe1c"
          }
        },
        "e09e639ccc4c446090d6c0ad53fd6316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8670bd06b6d4119b057400c7bc911ac",
            "placeholder": "​",
            "style": "IPY_MODEL_592d042aa7cf45cc8ca8951e4507e1b8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4cf551728dc44a71b6ad6ceee06e3e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b65a434505384c88a75276baddb2fff0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a3f7d2a2c33482999d8b4a47acb921d",
            "value": 2
          }
        },
        "be9503a14c4b411bbcf4ed5245dc9c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecdd4497912b48e5812e0705a573eab7",
            "placeholder": "​",
            "style": "IPY_MODEL_3b0d0070be3b4a549ddb4e53a9e424cb",
            "value": " 2/2 [00:50&lt;00:00, 22.50s/it]"
          }
        },
        "6696d694b72f449da36c6f85163dbe1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8670bd06b6d4119b057400c7bc911ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592d042aa7cf45cc8ca8951e4507e1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b65a434505384c88a75276baddb2fff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a3f7d2a2c33482999d8b4a47acb921d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecdd4497912b48e5812e0705a573eab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b0d0070be3b4a549ddb4e53a9e424cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjang750/fullstack-gpt/blob/master/RAG_0_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mRj7LfaLKGG",
        "outputId": "38fce6c1-c998-4f1d-95cd-d4c98dbf5bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformes.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ],
      "metadata": {
        "id": "-O7QXo3eM1uU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"kyujinpy/Ko-PlatYi-6B\" # model id\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545,
          "referenced_widgets": [
            "8e66ea9c0c904c3a8e49b77670e642e6",
            "e09e639ccc4c446090d6c0ad53fd6316",
            "4cf551728dc44a71b6ad6ceee06e3e48",
            "be9503a14c4b411bbcf4ed5245dc9c88",
            "6696d694b72f449da36c6f85163dbe1c",
            "b8670bd06b6d4119b057400c7bc911ac",
            "592d042aa7cf45cc8ca8951e4507e1b8",
            "b65a434505384c88a75276baddb2fff0",
            "7a3f7d2a2c33482999d8b4a47acb921d",
            "ecdd4497912b48e5812e0705a573eab7",
            "3b0d0070be3b4a549ddb4e53a9e424cb"
          ]
        },
        "id": "n_mDxqzhNho4",
        "outputId": "d376db75-5179-4c44-a380-84131df7176b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e66ea9c0c904c3a8e49b77670e642e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(78464, 4096, padding_idx=0)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaSdpaAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=512, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=512, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm()\n",
            "        (post_attention_layernorm): LlamaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=78464, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\"\n",
        "\n",
        "message = [\n",
        "    {\"role\":\"user\", \"content\":\"은행의 기준 금리에 대해서 설명해줘?\"}\n",
        "]\n",
        "\n",
        "encodeds = tokenizer.apply_chat_template(message,  return_tensors=\"pt\") # use pytorch\n",
        "\n",
        "model_inputs = encodeds.to(device)\n",
        "\n",
        "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "decoded = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "print(decoded[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVlEYif7SWJ9",
        "outputId": "5bd4cd65-bfff-4905-f83a-62668dc79e5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|startoftext|> [INST] <<SYS>>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "\n",
            "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
            "<</SYS>>\n",
            "\n",
            "은행의 기준 금리에 대해서 설명해줘? [/INST]\n",
            "\n",
            "은행은 특정 상품의 가격이나 통화 가치 상승에 자금을 차입해 수익을 창출합니다. 이러한 이자율도 은행으로서는 비용이며 일반적으로 시중 금리에 따른 이자율보다 낮은 수준으로 유지됩니다.\n",
            "\n",
            "은행의 기준 금리인 경우 보통 시장에서 적용되는 일반적인 이자율보다 낮은 수준으로 유지됩니다. 은행의 일반 은행 업무에 자금을 지원하는 경우 수익성이 비교적 낮은 은행은 일반 이자율보다 높은 금리를 제공해야 합니다.\n",
            "\n",
            "은행은 보통 다른 금리와 다르게 움직이는 시장 기준 금리와 같은 기준 금리 대신 자체적인 기준을 사용하는 경우가 많으며, 이러한 기준은 일반적으로 시중 은행 금리보다 낮은 수준으로 유지됩니다.\n",
            "\n",
            "하지만 일반적으로 기준 금리에서 0.05% 또는 0.1%의 '단위'가 존재합니다. 이 기준점은 거래량이 아주 많지 않거나 금융 시장이 혼란에 빠지고 있을 때와 같이 금융 시장이 비정상일 때 발생할 수 있는 변동성을 완화하는 데 사용됩니다. 금융 시장의 안정을 위해서는 이러한 상황에서 발생하는 변동성에 대해 일반적인 금리보다 약간 더 낮은 수준의 금리를 적용하도록 설정될 수 있습니다.\n",
            "\n",
            "은행 시스템의 일반 이자율보다 낮은 기준 금리와 거래량이 거의 발생하지 않고 혼란을 일으킬 수 있는 특정 상황에서만 일반적으로 사용되는 0.05% 또는 0.1%의 기준금리가 있다는 점에 유의하세요.<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale=True):\n",
        "  return \"UTF-8\"\n",
        "\n",
        "locale.getpreferredencoding = getpreferredencoding # 아래 패키지 설치 시 오류 방지"
      ],
      "metadata": {
        "id": "LzA4xQY3UQfZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain pypdf chromadb sentence-transformers faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD20hmXXUkv1",
        "outputId": "3768da14-e43e-4fd3-e14c-b4884a8c6c3a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from transformers import pipeline\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "text_generation_pipeline = pipeline (\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    temperature=0.2, # 할루시네이션 방지\n",
        "    return_full_text=True,\n",
        "    max_new_tokens=300,\n",
        ")\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "\n",
        "### [INST]\n",
        "instrunction: Answer the question based on your bank knowledge, If you don't know something, say you don't know it\n",
        "\n",
        "Here is context to help:\n",
        "\n",
        "{context}\n",
        "\n",
        "### QUESTION:\n",
        "{question}\n",
        "\n",
        "\n",
        "[/INST]\n",
        "\"\"\"\n",
        "\n",
        "koplatyi_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\",\"question\"],\n",
        "    template=prompt_template,\n",
        ")\n",
        "\n",
        "llm_chain = LLMChain(llm=koplatyi_llm, prompt=prompt)\n",
        "\n"
      ],
      "metadata": {
        "id": "vhaKFZmiVAAM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.schema.runnable import RunnablePassthrough"
      ],
      "metadata": {
        "id": "BUqPdRNHXs-Y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HHdTwCOYN_m",
        "outputId": "ddffc74b-1e9e-4af4-f1eb-b7bf7da441fb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"/content/guideline_20230630.pdf\")\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "texts = text_splitter.split_documents(pages)\n",
        "\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = \"jhgan/ko-sbert-nli\"\n",
        "encoding_kwargs = {'normalize_embeddings': True}\n",
        "\n",
        "hf = HuggingFaceEmbeddings(\n",
        "    model_name = model_name,\n",
        "    encode_kwargs = encoding_kwargs\n",
        ")\n",
        "\n",
        "db = FAISS.from_documents(texts, hf) # vector store\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={'k':3}\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZWO2onKZYq_y"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {\"context\":retriever,\"question\":RunnablePassthrough()}\n",
        "    | llm_chain\n",
        ")"
      ],
      "metadata": {
        "id": "inVuC7cWbRna"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Jwp3oWxbcA7B"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = rag_chain.invoke(\"자동 납부 동의자료 란?\")\n",
        "\n",
        "for i in result['context']:\n",
        "  print(f\"근거: {i.page_content} / 출처: {i.metadata['source']} - {i.metadata['page']} \\n\\n\")\n",
        "\n",
        "print(f\"답변: {result['text']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoHnxdZUdI04",
        "outputId": "601728ed-8ada-4a39-acb4-d80ab0549a23"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "근거: 1 / 8Ⅰ. 자동납부 동의자료란 ?\n",
            "  □ 자동납부 동의자료란 납부자가 자동납부 신청 시 요금청구기관에 제출하는 출금\n",
            "동의내역이 포함된 정보를 지칭\n",
            "  □ 요금청구기관은 납부자로부터 생성한 자동납부 동의자료를 자사의 자동이체서비\n",
            "스(CMS, 지로, 펌뱅킹) 제공기관을 통해 금융결제원 자동이체 통합관리 시스템으로 \n",
            "제출\n",
            "  ※ 자동납부동의자료 제출은 관련 법령*에 의거한 의무사항으로 , 납부자의 자동납부 \n",
            "신청 시 요금청구기관은 자동납부 등록정보와 자동납부 동의자료를 동시 송신\n",
            "하여야 함\n",
            "     * 전자금융거래법 제15조(추심이체의 출금동의 ), 전자금융거래법 시행령 제10조(출금동의의 \n",
            "방법), 전자금융감독규정 제6조(추심이체 출금 동의의 방법 등)에 의거하며 , 세부사항은 붙\n",
            "임1(관련 법령) 참조\n",
            "                             자동납부동의자료 개념도 / 출처: /content/guideline_20230630.pdf - 1 \n",
            "\n",
            "\n",
            "근거: 2 / 8Ⅱ. 자동납부 동의자료 생성\n",
            " 1. 자동납부 동의자료 내 정보내역\n",
            "  □ 요금청구기관은 다음의 납부자 정보내역을 포함한 자동납부 동의자료를 생성\n",
            "구 분 내 역\n",
            "필수 정보 요금청구기관명\n",
            " 납부자 출금은행\n",
            " 납부자 출금계좌번호\n",
            " 출금계좌 예금주명\n",
            " 예금주 생년월일 또는 주민번호대체번호 \n",
            " ※법인일 경우 사업자번호\n",
            "동의방법서면  예금주 날인 또는 서명주)\n",
            "녹취 ․ ARS  동의음성 또는 ARS 안내음\n",
            "전자문서  전자서명\n",
            "선택 정보  자동이체 서비스 종류\n",
            "신청인과 예금주가 다른 경우 신청인명\n",
            " 예금주와의 관계\n",
            " 신청인 날인 또는 서명\n",
            "    주) 단, 금융거래 제출서류 간소화로 자동납부 동의서류 상의 예금주 날인 또는 서명란이 삭제된 \n",
            "경우는 예외\n",
            "※ 요금청구기관은 자동납부 동의와 관련 없는 상기 정보 이외의 개인정보나  \n",
            "상담내역을 자동납부 동의자료에 포함할 수 없음 / 출처: /content/guideline_20230630.pdf - 2 \n",
            "\n",
            "\n",
            "근거: 3 / 8 \n",
            "2. 자동납부 동의방법\n",
            "  □ 요금청구기관은 관련 법령에서 정하고 있는 자동납부동의방법 (서면·녹취·음성\n",
            "응답시스템(ARS)·전자문서) 중 선택하여 , 필수 정보를 포함한 자동납부 동의자료를  \n",
            "생성\n",
            "  [서면]\n",
            "   ◦ 필수 정보가 포함된 요금청구기관의 서류 양식에 따라 납부자가 날인 또는 \n",
            "서명하는 방법으로 , 요금청구기관은 이를 스캐너· 디지털카메라 등 정보\n",
            "통신기기를 이용하여 이미지 파일로 변환\n",
            "  \n",
            "     ※ 서면 샘플양식은 붙임2 참조\n",
            "  [녹취]\n",
            " \n",
            "   ◦ 납부자 본인의 음성으로 필수 정보 확인 및 자동납부동의 여부가 녹음되는  \n",
            "방법으로 , 요금청구기관은 이를 오디오 파일로 변환\n",
            "  [음성응답시스템 (ARS, Audio Response System)]\n",
            "   ◦ 요금청구기관  고객센터의 ARS 음성 안내에 따라 납부자 본인이 육성 또는 \n",
            "버튼입력을 통해 필수정보를 확인하고 자동납부에 동의하는 방법으로 , \n",
            "요금청구기관은 이를 오디오 파일로 변환 / 출처: /content/guideline_20230630.pdf - 3 \n",
            "\n",
            "\n",
            "답변: \n",
            "\n",
            "### [INST]\n",
            "instrunction: Answer the question based on your bank knowledge, If you don't know something, say you don't know it\n",
            " \n",
            "Here is context to help:\n",
            "\n",
            "[Document(page_content='1 / 8Ⅰ. 자동납부 동의자료란 ?\\n  □ 자동납부 동의자료란 납부자가 자동납부 신청 시 요금청구기관에 제출하는 출금\\n동의내역이 포함된 정보를 지칭\\n  □ 요금청구기관은 납부자로부터 생성한 자동납부 동의자료를 자사의 자동이체서비\\n스(CMS, 지로, 펌뱅킹) 제공기관을 통해 금융결제원 자동이체 통합관리 시스템으로 \\n제출\\n  ※ 자동납부동의자료 제출은 관련 법령*에 의거한 의무사항으로 , 납부자의 자동납부 \\n신청 시 요금청구기관은 자동납부 등록정보와 자동납부 동의자료를 동시 송신\\n하여야 함\\n     * 전자금융거래법 제15조(추심이체의 출금동의 ), 전자금융거래법 시행령 제10조(출금동의의 \\n방법), 전자금융감독규정 제6조(추심이체 출금 동의의 방법 등)에 의거하며 , 세부사항은 붙\\n임1(관련 법령) 참조\\n                             자동납부동의자료 개념도', metadata={'source': '/content/guideline_20230630.pdf', 'page': 1}), Document(page_content='2 / 8Ⅱ. 자동납부 동의자료 생성\\n 1. 자동납부 동의자료 내 정보내역\\n  □ 요금청구기관은 다음의 납부자 정보내역을 포함한 자동납부 동의자료를 생성\\n구 분 내 역\\n필수 정보 요금청구기관명\\n 납부자 출금은행\\n 납부자 출금계좌번호\\n 출금계좌 예금주명\\n 예금주 생년월일 또는 주민번호대체번호 \\n ※법인일 경우 사업자번호\\n동의방법서면  예금주 날인 또는 서명주)\\n녹취 ․ ARS  동의음성 또는 ARS 안내음\\n전자문서  전자서명\\n선택 정보  자동이체 서비스 종류\\n신청인과 예금주가 다른 경우 신청인명\\n 예금주와의 관계\\n 신청인 날인 또는 서명\\n    주) 단, 금융거래 제출서류 간소화로 자동납부 동의서류 상의 예금주 날인 또는 서명란이 삭제된 \\n경우는 예외\\n※ 요금청구기관은 자동납부 동의와 관련 없는 상기 정보 이외의 개인정보나  \\n상담내역을 자동납부 동의자료에 포함할 수 없음', metadata={'source': '/content/guideline_20230630.pdf', 'page': 2}), Document(page_content='3 / 8 \\n2. 자동납부 동의방법\\n  □ 요금청구기관은 관련 법령에서 정하고 있는 자동납부동의방법 (서면·녹취·음성\\n응답시스템(ARS)·전자문서) 중 선택하여 , 필수 정보를 포함한 자동납부 동의자료를  \\n생성\\n  [서면]\\n   ◦ 필수 정보가 포함된 요금청구기관의 서류 양식에 따라 납부자가 날인 또는 \\n서명하는 방법으로 , 요금청구기관은 이를 스캐너· 디지털카메라 등 정보\\n통신기기를 이용하여 이미지 파일로 변환\\n  \\n     ※ 서면 샘플양식은 붙임2 참조\\n  [녹취]\\n \\n   ◦ 납부자 본인의 음성으로 필수 정보 확인 및 자동납부동의 여부가 녹음되는  \\n방법으로 , 요금청구기관은 이를 오디오 파일로 변환\\n  [음성응답시스템 (ARS, Audio Response System)]\\n   ◦ 요금청구기관  고객센터의 ARS 음성 안내에 따라 납부자 본인이 육성 또는 \\n버튼입력을 통해 필수정보를 확인하고 자동납부에 동의하는 방법으로 , \\n요금청구기관은 이를 오디오 파일로 변환', metadata={'source': '/content/guideline_20230630.pdf', 'page': 3})]\n",
            "\n",
            "### QUESTION:\n",
            "자동 납부 동의자료 란?\n",
            "\n",
            "\n",
            "[/INST]\n",
            "\n",
            "답변: 자동납부동의자료란 납부자가 자동납부 신청 시 요금청구기관에 제출하는 출금동의내역이 포함된 정보를 지칭합니다.\n"
          ]
        }
      ]
    }
  ]
}